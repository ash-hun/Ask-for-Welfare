import streamlit as st
import chromadb
import re
import os
import io
import utility
from config import score_threshold, search_k, llm_model, user_img, bot_img, device, EMBEDDING_MODEL_PATH, CHROMA_DB_PATH
from actions.stream_handler import StreamHandler

from langchain.schema import ChatMessage
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

from streamlit_chat import message # Chatbot UI
from audio_recorder_streamlit import audio_recorder # ìŒì„±ë…¹ìŒ
from pydub import AudioSegment # ë…¹ìŒ íŒŒì¼ ì €ì¥
from openai import OpenAI # STT


# ==========================================================================================================================================================================
# â­ï¸ Global Config â­ï¸
# ==========================================================================================================================================================================
st.set_page_config(
    page_title="ë¬¼ì–´ë³´ì¥",
    page_icon="ğŸ‘‹",
)

# Load Embedding Model
try:
    model_dir = EMBEDDING_MODEL_PATH
    embedding = SentenceTransformerEmbeddings(model_name=model_dir, model_kwargs={'device': device}, encode_kwargs={'normalize_embeddings':True})
except:
    print('Please Check Embedding Model')
    pass


# Load Chroma DB (=Vector DB)
try:
    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)

    collection_name = "ko_sroberta_multitask_seed_777_lr_1e-5"

    vectorstore = Chroma(
        client= chroma_client,
        collection_name= collection_name,
        embedding_function= embedding,
        persist_directory=CHROMA_DB_PATH
    )
except:
    print('Please Check ChromaDB')
    pass

# Initializing RAG System
try:
    # ì„ê³„ì  ê¸°ë°˜ : ì ì ˆí•œ threshold ê°’ ì„ ì •ì´ í•„ìˆ˜ì„.
    retriever = vectorstore.as_retriever(search_type="similarity_score_threshold", search_kwargs={'k': search_k ,'score_threshold': score_threshold})

    ## llm í”„ë¡¬í”„íŒ…
    # ê²€ìƒ‰ëœ ë¬¸ì¥ ë‚´ì—ì„œë§Œ ëŒ€ë‹µí•˜ë„ë¡ í•˜ê³  ë‚´ìš©ì„ ë°”ê¾¸ì§€ ëª»í•˜ê²Œ í”„ë¡¬í”„íŠ¸ ì‘ì„±

    system_template="""Use the following pieces of context to answer the users question shortly.
    Given the following summaries of a long document and a question, create a final answer with references ("source_documents"), use "source_documents" in capital letters regardless of the number of sources.
    But Don't say word of source_documents.
    If you don't know the answer, just say that "I don't know", don't try to make up an answer.
    ----------------
    {context}

    You MUST answer in Korean"""

    messages = [
        SystemMessagePromptTemplate.from_template(system_template),
        HumanMessagePromptTemplate.from_template("{question}")
    ]

    prompt = ChatPromptTemplate.from_messages(messages)

    chain_type_kwargs = {"prompt": prompt}
except:
    print('Please Check Backend Dataflow')
    pass
# ==========================================================================================================================================================================


# ==========================================================================================================================================================================
# ğŸ”¥ Define Custom Functions 
# ==========================================================================================================================================================================
def stt():
    ## (ë…¹ìŒ) ë§ˆì´í¬ ë²„íŠ¼ ë‘ë²ˆ ëˆ„ë¥´ë©´ ì‚¬ìš©ì ìŒì„±ì‹ í˜¸ mp3 í˜•ì‹ìœ¼ë¡œ ì €ì¥ - ./output.mp3
    audio_bytes = audio_recorder(text="")

    if audio_bytes:
        st.audio(audio_bytes, format="audio/wav")

    ## ë…¹ìŒ ì™„ë£Œë˜ë©´ mp3 í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê³  SST í•¨ìˆ˜ ì´ìš©í•˜ì—¬ text ë³€í™˜
    if audio_bytes is not None:
        ## mp3 í˜•ì‹ìœ¼ë¡œ ì €ì¥
        audio_segmant = AudioSegment.from_file(io.BytesIO(audio_bytes))
        # Export the audio file
        audio_segmant.export('./audio/output.mp3', format='mp3')

        # mp3 íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ STT ì ìš©
        client = OpenAI()
        sst_text = utility.STT("./audio/output.mp3", client)

        clean_text = sst_text.replace("\n", "")

        # ìœ ì € inputì°½ì— í…ìŠ¤íŠ¸ ì‹¬ì–´ì¤Œ.
        js = f"""
        <script>
        function insertText(dummy_var_to_force_repeat_execution) {{
        var chatInput = parent.document.querySelector('textarea[data-testid="stChatInput"]');
        var nativeInputValueSetter = Object.getOwnPropertyDescriptor(window.HTMLTextAreaElement.prototype, "value").set;
        nativeInputValueSetter.call(chatInput, "{clean_text}");
        var event = new Event('input', {{ bubbles: true}});
        chatInput.dispatchEvent(event);
        }}
        insertText({len(st.session_state['messages'])});
        </script>
        """
        st.components.v1.html(js)

        audio_bytes = None 

def tts(): # TTS ê¸°ëŠ¥
    try:
        # st.sidebar.write(final_response)
        utility.chat_output_value(final_response)
        audio_file = open('./output.mp3', 'rb')
        audio_bytes = audio_file.read()

        st.sidebar.audio(audio_bytes, format='audio/mp3')
    except:
        st.sidebar.write('ìµœê·¼ ë‹µë³€ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”.')
        audio_file = open('./audio/output_error.mp3', 'rb')
        audio_bytes = audio_file.read()

        st.sidebar.audio(audio_bytes, format='audio/mp3')

def llm_chatbot(question):
    """ llm_chatbot

    ì‚¬ìš©ìê°€ ì¿¼ë¦¬(question)ë¥¼ ì…ë ¥í•˜ë©´ LangChainì„ í†µí•´ embedding ëª¨ë¸ì„ ê±°ì³ Vector DBì— ë“¤ì–´ê°„ ë¬¸ì„œë¥¼ Retrieverí•˜ì—¬
    ê´€ë ¨ì„±ì´ ê¹Šì€ ë¬¸ì„œë¥¼ ì°¾ëŠ”ë‹¤. ì´ë•Œ, ì°¾ì•„ë‚¸ ê²°ê³¼(ë¬¸ì„œ ê°œìˆ˜)ì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ ì²˜ë¦¬ë¥¼ ì´í–‰í•œë‹¤.

    Args:
        question (str): _description_

    Returns:
        _type_: _description_
    """
    query = question
    result = chain(query)

    # ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
    if len(result['source_documents']) > 0: # ë¬¸ì„œ í•˜ë‚˜ë¼ë„ ê²€ìƒ‰ëœ ê²½ìš°
        # title ë°˜í™˜ì„ ìœ„í•œ ì½”ë“œ 
        lst = []
        for i in range(len(result['source_documents'])):
            try:
                # ì‹œë„: metadata['title']ì— ì ‘ê·¼
                title_link = "[" + result['source_documents'][i].metadata['title'] + "](" + result['source_documents'][i].metadata['url'] + ")"
                #title_link = "www.naver.com"
                lst.append(title_link)
            except KeyError:
                # ì˜ˆì™¸ ì²˜ë¦¬: 'title' í‚¤ê°€ ì—†ì„ ê²½ìš°
                continue
        return(result['result'], lst)
    else: # ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ëŠ”ê²½ìš°
        return ((f"'{result['query']}' ì— ëŒ€í•œ ë‚´ìš©ì€ ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤."), '')

def set_list(docs):
    """ set_list
    ë¬¸ì„œ ë‚´ìš©ì´ ì¤‘ë³µë  ê²½ìš° ì œê±°í•œë‹¤.

    Args:
        docs (_type_) : None check duplicate data

    Returns:
        unique_list (list) : Delete duplicate data
    """

    unique_list = []
    seen = set()

    for item in docs:
        if item not in seen:
            unique_list.append(item)
            seen.add(item)
    return unique_list

def modeloutput(prompt):
    """ modeloutput

    ì‹¤ì œ ì¶œë ¥ë  ì±—ë´‡ë‚´ìš©ì„ ì •ì œí•œë‹¤.

    Args:
        prompt (str): Output prompt

    Returns:
        str : Transform output prompt
    """
    prompt, docs = llm_chatbot(prompt)
    prompt = re.sub(r'\[source_documents\]|\(source_documents\)|source_documents', '', prompt)
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì—°ê²°
    if len(docs) == 0:
        return (f"{prompt}", f"ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ê²€ìƒ‰ í•´ë³´ì‹œê±°ë‚˜, 'aaa@aaa.com'ì„ í†µí•´ ë¬¸ì˜ ë°”ëë‹ˆë‹¤.")
    else: 
        joined_docs = ', '.join(map(str, set_list(docs)))
        return (f"{prompt}", f"ì´ì™€ ê´€ë ¨ëœ ë³µì§€ì œë„ëŠ” **{joined_docs}** ë“±ì´ ìˆìŠµë‹ˆë‹¤.")

# ==========================================================================================================================================================================

# ==========================================================================================================================================================================
# âœ… Interface
# ==========================================================================================================================================================================
# streamlit run webapp.py
if __name__ == "__main__":
    # ------------------------------------------------------------------
    # Setting Styling
    # ------------------------------------------------------------------
    with open('./css.css', 'r', encoding='utf-8') as file:
        css = file.read()
    st.markdown(f'<style>{css}</style>', unsafe_allow_html=True)

    # ------------------------------------------------------------------
    # Layout Grid
    # ------------------------------------------------------------------
    col1, col2= st.sidebar.columns(2)
    # ------------------------------------------------------------------
    
    # ------------------------------------------------------------------
    # Sidebar Interface
    # ------------------------------------------------------------------
    utility.add_logo()
    with st.sidebar.container():
        with col1:
            # st.sidebar.button("ğŸ¤", on_click=stt) #ğŸ¤
            ## (ë…¹ìŒ) ë§ˆì´í¬ ë²„íŠ¼ ë‘ë²ˆ ëˆ„ë¥´ë©´ ì‚¬ìš©ì ìŒì„±ì‹ í˜¸ mp3 í˜•ì‹ìœ¼ë¡œ ì €ì¥ - ./output.mp3
            audio_bytes = audio_recorder(text="")

            if audio_bytes:
                st.audio(audio_bytes, format="audio/wav")

            ## ë…¹ìŒ ì™„ë£Œë˜ë©´ mp3 í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê³  SST í•¨ìˆ˜ ì´ìš©í•˜ì—¬ text ë³€í™˜
            if audio_bytes is not None:
                ## mp3 í˜•ì‹ìœ¼ë¡œ ì €ì¥
                audio_segmant = AudioSegment.from_file(io.BytesIO(audio_bytes))
                # Export the audio file
                audio_segmant.export('./audio/output.mp3', format='mp3')

                # mp3 íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ STT ì ìš©
                client = OpenAI()
                sst_text = utility.STT("./audio/output.mp3", client)

                clean_text = sst_text.replace("\n", "")

                # ìœ ì € inputì°½ì— í…ìŠ¤íŠ¸ ì‹¬ì–´ì¤Œ.
                js = f"""
                <script>
                function insertText(dummy_var_to_force_repeat_execution) {{
                var chatInput = parent.document.querySelector('textarea[data-testid="stChatInput"]');
                var nativeInputValueSetter = Object.getOwnPropertyDescriptor(window.HTMLTextAreaElement.prototype, "value").set;
                nativeInputValueSetter.call(chatInput, "{clean_text}");
                var event = new Event('input', {{ bubbles: true}});
                chatInput.dispatchEvent(event);
                }}
                insertText({len(st.session_state['messages'])});
                </script>
                """
                st.components.v1.html(js)

                audio_bytes = None 
        with col2:
            st.sidebar.button("ğŸ§", on_click=tts) # ğŸ”ˆ
        api_key = st.sidebar.text_input('API KEYë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
        api_button = st.sidebar.button('API KEY ì…ë ¥')

        if api_button:
            os.environ["OPENAI_API_KEY"] = api_key
    # ------------------------------------------------------------------
    
    # ------------------------------------------------------------------
    # Main Contents Interface
    # ------------------------------------------------------------------
    st.markdown('''  > **â€» ì‹¤í–‰í™˜ê²½ì˜ í™˜ê²½ë³€ìˆ˜ì— OPENAI_APIKEYê°€ ìˆì§€ì•Šë‹¤ë©´ ì¢Œì¸¡ì— API_Keyë¥¼ ì…ë ¥í•œ ë’¤ ì‚¬ìš©í•´ì£¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤ğŸ˜†**   
                ë˜í•œ ë³¸ ì±„íŒ…ì€ ë³¸ì¸ì˜ ìƒí™©ê³¼ í•„ìš”í•œ ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ê·¸ì— ëŒ€í•œ ì˜ë¯¸ê°€ë°˜ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  
                ì´ì™¸ì˜ ëŒ€í™”ëŠ” êµ¬í˜„ë˜ì–´ ìˆì§€ ì•Šìœ¼ë‹ˆ ì°¸ê³ ë°”ëë‹ˆë‹¤ :) ''')
    st.divider()

    if "messages" not in st.session_state:
        st.session_state["messages"] = [ChatMessage(role="assistant", content="ì €ëŠ” 'ë‚˜ì—ê²Œ í˜ì´ë˜ëŠ” ë³µì§€ì„œë¹„ìŠ¤ 2023' ì±…ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³µì§€ì •ì±…ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ë³µì§€ ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")]

    for msg in st.session_state.messages:
        st.chat_message(msg.role).write(msg.content)

    if prompt := st.chat_input('ë³µì§€ ì •ì±…ì„ ë¬¼ì–´ë³´ì¥!'):
        st.session_state.messages.append(ChatMessage(role="user", content=prompt))
        st.chat_message("user").write(prompt)

        if not os.environ.get("OPENAI_API_KEY"):
            st.info("Please add your OpenAI API key to continue.")
            st.stop()

        with st.chat_message("assistant"):
            container = st.empty()
            stream_handler = StreamHandler(container)
            llm = ChatOpenAI(model_name=llm_model, temperature=0, streaming=True, callbacks=[stream_handler])

            chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever = retriever,
                return_source_documents=True,
                chain_type_kwargs=chain_type_kwargs
            )

            result = chain(prompt)
            st.session_state.messages.append(ChatMessage(role="assistant", content=result['result']))

            lst = []
            for i in range(len(result['source_documents'])):
                try:
                    title_link = "[" + result['source_documents'][i].metadata['title'] + "](" + result['source_documents'][i].metadata['url'] + ")"
                    lst.append(title_link)
                except KeyError:
                    lst.append('ê´€ë ¨ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.')
            
            joined_docs = ', '.join(map(str, set_list(lst)))
            docs = f"**{joined_docs}** ë“±ì´ ìˆìŠµë‹ˆë‹¤."

            final_response = f"""
            {result['result']}  
            {"**ì´ì™€ ê´€ë ¨ëœ ë³µì§€ì œë„ëŠ”**"}
            {docs} 
            """
            container.markdown(final_response)
    # ------------------------------------------------------------------
